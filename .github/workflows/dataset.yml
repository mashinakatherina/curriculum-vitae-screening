name: Dataset Workflow
on: [workflow_dispatch]
jobs:
  LoadDataset:
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install kaggle API
        run: pip install kaggle
      - name: download dataset
        env:
          KAGGLE_USERNAME: viacheslavgorash
          KAGGLE_KEY: ${{secrets.KAGGLEKEY}}
        run: kaggle datasets download leenardeshmukh/curriculum-vitae
      - name: unpack dataset archive
        run: unzip curriculum-vitae.zip
      - name: install script requirements
        run: pip install -r src/requirements.txt
      - name: fill database
        env:
          DB_USERNAME: github
          DB_PASSWORD: ${{secrets.DBPASSWORD}}
        run: python src/dataset_loading.py "Curriculum Vitae.csv"

  PreprocessDataset:
    runs-on: ubuntu-latest
    needs: LoadDataset
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r src/requirements.txt
      - name: process_data
        env:
          DB_USERNAME: github
          DB_PASSWORD: ${{secrets.DBPASSWORD}}
        run: python src/dataset_processing.py
